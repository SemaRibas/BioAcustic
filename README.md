# ğŸ¸ BioAcustic - Classificador de AnfÃ­bios com Deep Learning

Sistema completo de reconhecimento e classificaÃ§Ã£o de espÃ©cies de anfÃ­bios baseado em vocalizaÃ§Ãµes utilizando Deep Learning e Web Technologies.

![Status](https://img.shields.io/badge/status-development-yellow)
![Python](https://img.shields.io/badge/python-3.8+-blue)
![TensorFlow](https://img.shields.io/badge/tensorflow-2.10+-orange)
![License](https://img.shields.io/badge/license-MIT-green)

---

## ğŸ“‹ Ãndice

- [Sobre o Projeto](#sobre-o-projeto)
- [Arquitetura](#arquitetura)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [Uso RÃ¡pido](#uso-rÃ¡pido)
- [Pipeline Completo](#pipeline-completo)
- [Deployment (Servidor 24/7)](#deployment)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [DocumentaÃ§Ã£o](#documentaÃ§Ã£o)
- [Contribuindo](#contribuindo)
- [LicenÃ§a](#licenÃ§a)

---

## ğŸ¯ Sobre o Projeto

O **BioAcustic** Ã© uma aplicaÃ§Ã£o web que utiliza redes neurais convolucionais (CNNs) para identificar espÃ©cies de anfÃ­bios atravÃ©s de suas vocalizaÃ§Ãµes. O sistema processa Ã¡udio em tempo real no navegador usando TensorFlow.js.

### CaracterÃ­sticas Principais

- âœ… **100% Cliente-Side**: InferÃªncia no navegador (privacidade!)
- ï¿½ **Treinamento no Navegador**: Treine modelos sem instalar Python! (NOVO)
- ï¿½ğŸµ **Processamento de Ãudio**: ConversÃ£o de Ã¡udio para Mel-Espectrogramas
- ğŸ§  **Deep Learning**: Transfer Learning com MobileNetV2/EfficientNet (Python) ou CNN simples (Navegador)
- ğŸ¨ **Interface Moderna**: UI responsiva com Tailwind CSS
- ğŸ“Š **VisualizaÃ§Ã£o**: Espectrogramas e resultados em tempo real
- ğŸ¤ **GravaÃ§Ã£o ao Vivo**: Suporte para microfone

### ğŸ†• Novidade: Treinamento no Navegador

Agora vocÃª pode treinar modelos diretamente no navegador sem precisar instalar Python ou TensorFlow! Perfeito para:
- Prototipagem rÃ¡pida
- DemonstraÃ§Ãµes educacionais
- Projetos com poucas espÃ©cies (2-10)
- MÃ¡xima privacidade (dados nÃ£o saem do navegador)

[ğŸ“– Ver Guia Completo de Treinamento no Navegador](BROWSER_TRAINING_GUIDE.md)

---

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         FRONTEND (Navegador)            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  HTML5 + Tailwind CSS              â”‚ â”‚
â”‚  â”‚  JavaScript (ESM) + TensorFlow.js  â”‚ â”‚
â”‚  â”‚  Processamento de Ãudio (Web API)  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â–²
                  â”‚ (Modelo convertido)
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         BACKEND (Python)                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  1. AquisiÃ§Ã£o de Dados (Xeno-canto)â”‚ â”‚
â”‚  â”‚  2. PrÃ©-processamento (librosa)    â”‚ â”‚
â”‚  â”‚  3. Treinamento (TensorFlow/Keras) â”‚ â”‚
â”‚  â”‚  4. ConversÃ£o (tensorflowjs)       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos

- **Python 3.8+**
- **Node.js** (opcional, para servidor HTTP)
- **GPU NVIDIA** (recomendado para treinamento)

### 1. Clonar RepositÃ³rio

```bash
git clone https://github.com/seu-usuario/bioacustic.git
cd bioacustic
```

### 2. Configurar Ambiente Python

```bash
# Criar ambiente virtual
python -m venv venv

# Ativar (Windows)
venv\Scripts\activate

# Ativar (Linux/Mac)
source venv/bin/activate

# Instalar dependÃªncias
pip install -r backend/requirements.txt
```

### 3. Verificar InstalaÃ§Ã£o

```bash
python -c "import tensorflow as tf; print('TensorFlow:', tf.__version__)"
python -c "import librosa; print('Librosa OK')"
```

---

## âš¡ Uso RÃ¡pido

### OpÃ§Ã£o 1: Treinamento no Navegador (Recomendado para Iniciantes)

**Sem instalaÃ§Ã£o! Zero configuraÃ§Ã£o!**

1. Inicie um servidor HTTP simples:
   ```bash
   # Python 3
   python -m http.server 8000 --directory frontend
   
   # Ou use qualquer servidor HTTP
   ```

2. Acesse a pÃ¡gina de treinamento:
   ```
   http://localhost:8000/train.html
   ```

3. Siga o guia interativo:
   - Adicione pelo menos 5 Ã¡udios de cada espÃ©cie (mÃ­nimo 2 espÃ©cies)
   - Clique em "Treinar Modelo"
   - Aguarde o treinamento (~5-15 minutos)
   - Salve o modelo
   - Use no app principal!

**ğŸ“– [Guia Completo de Treinamento no Navegador](BROWSER_TRAINING_GUIDE.md)**

---

### OpÃ§Ã£o 2: Pipeline Python (AvanÃ§ado - Maior AcurÃ¡cia)

### OpÃ§Ã£o A: Usar Modelo PrÃ©-treinado (Recomendado)

Se vocÃª jÃ¡ tem um modelo treinado:

```bash
# 1. Converter modelo para TensorFlow.js
python backend/scripts/04_convert_to_tfjs.py

# 2. Iniciar servidor HTTP
cd frontend
python -m http.server 8000

# 3. Abrir navegador
# http://localhost:8000
```

### OpÃ§Ã£o B: Treinar Seu PrÃ³prio Modelo

Veja [Pipeline Completo](#pipeline-completo) abaixo.

---

## ğŸ“¦ Pipeline Completo

### Fase 1: AquisiÃ§Ã£o de Dados

Baixar vocalizaÃ§Ãµes do Xeno-canto:

```bash
python backend/scripts/01_download_data.py
```

**ConfiguraÃ§Ãµes** (editar no script):
- `SPECIES_LIST`: Lista de espÃ©cies
- `RECORDINGS_PER_SPECIES`: NÃºmero de gravaÃ§Ãµes por espÃ©cie
- `QUALITY`: Qualidade mÃ­nima (A, B, C)

### Fase 2: PrÃ©-processamento

Converter Ã¡udios para Mel-Espectrogramas:

```bash
python backend/scripts/02_preprocess_audio.py
```

**ParÃ¢metros**:
- Sample Rate: 22050 Hz
- DuraÃ§Ã£o: 3 segundos
- Mel Bands: 128
- FFT Size: 2048

### Fase 3: Treinamento

Treinar modelo CNN com Transfer Learning:

```bash
python backend/scripts/03_train_model.py
```

**ConfiguraÃ§Ãµes**:
- Arquitetura: `mobilenet` ou `efficientnet`
- Ã‰pocas: 50
- Batch Size: 32
- Learning Rate: 0.0001

**SaÃ­da**:
```
backend/models/
â””â”€â”€ amphibian_classifier_mobilenet_YYYYMMDD_HHMMSS/
    â”œâ”€â”€ best_model.h5
    â”œâ”€â”€ final_model.h5
    â”œâ”€â”€ class_names.json
    â”œâ”€â”€ config.json
    â””â”€â”€ logs/
```

### Fase 4: ConversÃ£o para Web

Converter modelo para TensorFlow.js:

```bash
python backend/scripts/04_convert_to_tfjs.py
```

**SaÃ­da**:
```
frontend/assets/model/
â”œâ”€â”€ model.json
â”œâ”€â”€ group1-shard1of*.bin
â”œâ”€â”€ metadata.json
â””â”€â”€ class_names.json
```

### Fase 5: Deploy da AplicaÃ§Ã£o Web

```bash
cd frontend
python -m http.server 8000
```

Abra: `http://localhost:8000`

---

## ğŸ“‚ Estrutura do Projeto

```
BioAcustic/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ 01_download_data.py
â”‚   â”‚   â”œâ”€â”€ 02_preprocess_audio.py
â”‚   â”‚   â”œâ”€â”€ 03_train_model.py
â”‚   â”‚   â””â”€â”€ 04_convert_to_tfjs.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ raw/              # Ãudios originais
â”‚   â”‚   â””â”€â”€ processed/        # Espectrogramas
â”‚   â”œâ”€â”€ models/               # Modelos treinados
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ js/
â”‚   â”‚   â”œâ”€â”€ app.js           # AplicaÃ§Ã£o principal
â”‚   â”‚   â”œâ”€â”€ model.js         # Gerenciador de modelo
â”‚   â”‚   â”œâ”€â”€ audio.js         # Processamento de Ã¡udio
â”‚   â”‚   â””â”€â”€ ui.js            # Interface de usuÃ¡rio
â”‚   â””â”€â”€ assets/
â”‚       â””â”€â”€ model/           # Modelo TensorFlow.js
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ DIRETRIZES_COMPLETAS.md
â”‚   â””â”€â”€ EVALUATION_GUIDE.md
â”‚
â””â”€â”€ README.md
```

---

## ğŸ“š DocumentaÃ§Ã£o

- **[Diretrizes Completas](./docs/DIRETRIZES_COMPLETAS.md)**: Guia detalhado de todas as fases
- **[Guia de AvaliaÃ§Ã£o](./docs/EVALUATION_GUIDE.md)**: MÃ©tricas e testes de campo
- **API Reference**: DocumentaÃ§Ã£o inline no cÃ³digo

---

## ğŸ§ª Testes

### Teste de Modelo (Navegador)

```bash
cd frontend/assets/model
python -m http.server 8000
```

Abrir: `http://localhost:8000/test_model.html`

### Teste de AcurÃ¡cia (Python)

```python
from backend.scripts.03_train_model import AmphibianClassifier

classifier = AmphibianClassifier()
# ... carregar dados de teste
results = classifier.evaluate(X_test, y_test)
```

---

## ğŸš€ Deployment

### Manter Servidor Online 24/7

O BioAcustic pode ser implantado de vÃ¡rias formas:

#### OpÃ§Ã£o 1: GitHub Pages (Recomendado) â­
- **Gratuito** e **FÃ¡cil**
- Online em 5 minutos
- HTTPS automÃ¡tico

```bash
# Enviar para GitHub
git init
git add .
git commit -m "Deploy BioAcustic"
git push

# Ativar GitHub Pages em Settings â†’ Pages
```

**Acesse:** `https://seu-usuario.github.io/bioacustic/`

#### OpÃ§Ã£o 2: ServiÃ§o Windows (Local)
```powershell
# Execute como Administrador
.\install_service.ps1
```
Servidor rodarÃ¡ automaticamente sempre que ligar o PC.

#### OpÃ§Ã£o 3: Docker
```bash
docker-compose up -d
```

#### OpÃ§Ã£o 4: VPS/Cloud
- DigitalOcean ($6/mÃªs)
- AWS Free Tier (1 ano grÃ¡tis)
- Heroku, Netlify, Vercel (grÃ¡tis)

**ğŸ“– Guias Completos:**
- **InÃ­cio RÃ¡pido:** `QUICK_DEPLOY.md`
- **Todas OpÃ§Ãµes:** `DEPLOYMENT_GUIDE.md`

---

## ğŸ“ Tecnologias Utilizadas

### Backend
- **Python 3.8+**
- **TensorFlow/Keras**: Deep Learning
- **librosa**: Processamento de Ã¡udio
- **NumPy/Pandas**: ManipulaÃ§Ã£o de dados
- **scikit-learn**: MÃ©tricas e validaÃ§Ã£o

### Frontend
- **HTML5**: Estrutura
- **Tailwind CSS**: EstilizaÃ§Ã£o
- **JavaScript (ESM)**: LÃ³gica
- **TensorFlow.js**: InferÃªncia no navegador
- **Web Audio API**: Processamento de Ã¡udio

---

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/NovaFuncionalidade`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona nova funcionalidade'`)
4. Push para a branch (`git push origin feature/NovaFuncionalidade`)
5. Abra um Pull Request

---

## ğŸ“Š Roadmap

- [x] Pipeline completo de treinamento
- [x] Interface web bÃ¡sica
- [x] InferÃªncia no navegador
- [ ] AdiÃ§Ã£o de mais espÃ©cies
- [ ] API backend opcional (Python/FastAPI)
- [ ] App mobile (React Native)
- [ ] IntegraÃ§Ã£o com banco de dados de biodiversidade
- [ ] Modo offline (PWA)

---

## ğŸ› Issues Conhecidos

- **PrÃ©-processamento no navegador**: Pode haver pequenas diferenÃ§as entre espectrogramas gerados em Python vs. JavaScript. Para produÃ§Ã£o, considere usar uma API backend.
- **Performance**: Primeira inferÃªncia Ã© lenta (carregamento de modelo). Warump resolve.
- **Compatibilidade**: Testado apenas em Chrome/Edge. Firefox e Safari podem ter limitaÃ§Ãµes.

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

---

## ğŸ‘¥ Autores

- **Projeto BioAcustic** - Desenvolvido para fins educacionais e cientÃ­ficos

---

## ğŸ™ Agradecimentos

- **Xeno-canto**: Pela disponibilizaÃ§Ã£o de dados de Ã¡udio
- **TensorFlow Team**: Pela excelente biblioteca
- **Comunidade de BioacÃºstica**: Pelo conhecimento compartilhado

---

## ğŸ“ Contato

- **Issues**: Use o sistema de issues do GitHub
- **DiscussÃµes**: Aba de Discussions do repositÃ³rio

---

## ğŸŒŸ Star History

Se este projeto foi Ãºtil para vocÃª, considere dar uma â­!

---

**Made with ğŸ¸ and ğŸ§  for Amphibian Conservation**
